{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W0WaCDM MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamente a quando fatto per LambdaCMD model:\n",
    "Steps:\n",
    "* 1- Set the cosmology: H0=67.5, ombh2=0.022, omch2=0.122, omk=0, omrh2= 2.47*10^-5(this values is taken from the internet), omega_Lambda = 0.681   * \n",
    "* 2- Compute the distances modulus for each redshifts z took by the file \"binned_data\" (40 values)\n",
    "* 3- Compute the chi square and verify that is equal to 0 (or so close to 0)\n",
    "* 4- Make the best fit with minimize to find the parameters\n",
    "\n",
    "*N.B: ombh2 = (barion density)*h^2; omch2 = (cold dark matter density)^2; omk = curvature density (these values is taken by CAMB's Tutorial)\n",
    "*N.B: ombh2 + omch2 = 0.144 --> 0.144/(0.672)**2 = 0.319 (omega_matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import math as m\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emcee\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import camb\n",
    "import pandas as pd\n",
    "\n",
    "# Import pyACC logger\n",
    "from pyACC.helpers import Logger\n",
    "\n",
    "# Set the logger\n",
    "print = Logger(\"pyACC.CosmologicalDistances\")\n",
    "\n",
    "# Import integration class\n",
    "from pyACC.Cosmology.distances import Dc, Dc_w0wa, Dc_w\n",
    "\n",
    "from scipy.optimize import minimize #to make best fit of the chi square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ THE DATA\n",
    "# Load the data\n",
    "file_path = 'binned_data.txt'\n",
    "\n",
    "# Read the first line to get the header\n",
    "with open(file_path, 'r') as file:\n",
    "    header_line = file.readline().strip()\n",
    "    header = header_line.lstrip('#').strip()\n",
    "\n",
    "# Remove the last word from the header (assumed to be 'biascor')\n",
    "header_words = header.split()\n",
    "header_words.pop()\n",
    "header = ' '.join(header_words)\n",
    "\n",
    "# Read the rest of the file into a DataFrame\n",
    "data = pd.read_csv(file_path, sep='\\s+', skiprows=1, header=None)\n",
    "data.columns = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Hubble function and set the cosmology\n",
    "def hubble_function_w0wa(z, Omega_m, Omega_r, Omega_k, Omega_lambda, w0, wa, H0):\n",
    "    # Calculate the dark energy contribution\n",
    "    dark_energy_contribution = (1 + z)**(3 * (1 + w0 + wa)) * np.exp(-3 * wa * z / (1 + z))\n",
    "    \n",
    "    # Calculate H(z)\n",
    "    Hz = H0 * np.sqrt(\n",
    "        Omega_m * (1 + z)**3 +\n",
    "        Omega_r * (1 + z)**4 +\n",
    "        Omega_k * (1 + z)**2 +\n",
    "        Omega_lambda * dark_energy_contribution\n",
    "    )\n",
    "    \n",
    "    return Hz\n",
    "\n",
    "# Set the cosmology\n",
    "H0 = 67.5\n",
    "omega_matter = 0.319\n",
    "omega_rad = 2.47e-5/(0.672)**2 # 0.00005 \n",
    "omega_k = 0\n",
    "omega_L = 0.681 # 1 - omega_matter - omega_rad - omega_k\n",
    "w0 = -0.5\n",
    "wa = -1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "d = data['mb'].values\n",
    "dmb = data['dmb'].values\n",
    "z_list = data['zcmb'].values\n",
    "\n",
    "\n",
    "\n",
    "mu = []\n",
    "for z_prime in z_list:\n",
    "    mu.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25) #mu.append(5*np.log10(Dc(hubble_function,z_prime,0.319,0,-1,68)*(1+z_prime)) + 25)\n",
    "#print(mu)\n",
    "'''\n",
    "# Plot mu vs z (to verify that the distances are right)\n",
    "plt.plot(z_list, mu, 'o')\n",
    "plt.xlabel('Redshift z')\n",
    "plt.ylabel('Distance Modulus mu')\n",
    "plt.title('Distance Modulus vs Redshift')\n",
    "plt.show()\n",
    "'''\n",
    "data['mb'] = mu\n",
    "# Define the likelihood function\n",
    "def ln_likelihood(params, data, cov_inv):\n",
    "    H0, Omega_mat, Omega_rad, Omega_k, Omega_L, w0, wa = params \n",
    "    #print(H0, Om0)\n",
    "    # Check if the parameters are within the physical range\n",
    "    if Omega_mat or Omega_rad or Omega_k or Omega_L < 0:\n",
    "        return -np.inf\n",
    "    if w0 < -2 or w0 > 0:\n",
    "        return -np.inf\n",
    "    if wa < -3 or wa > 0:\n",
    "        return -np.inf\n",
    "    z = data['zcmb'].values\n",
    "    d = data['mb'].values \n",
    "    mu = []\n",
    "    for z_prime in z_list:\n",
    "        mu.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25) #it is equivalent to get_mu(z, H0, Om0, w0, wa)\n",
    "    diff = d - mu\n",
    "    term1 = -0.5 * diff @ cov_inv @ diff # @ is the matrix multiplication\n",
    "    \n",
    "    return term1 \n",
    "\n",
    "def neg_ln_likelihood(params, data, cov_inv):\n",
    "    return -2*ln_likelihood(params, data, cov_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data and covariance inverse matrix\n",
    "z = data['zcmb'].values\n",
    "d = data['mb'].values + 19.3\n",
    "dmb = data['dmb'].values\n",
    "\n",
    "# Compute the covariance matrix\n",
    "Sigma = np.diag(dmb**2)\n",
    "cov_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "# Initial guess for the parameters [H0, Om0]\n",
    "initial_guess = [67.5, 0.319, 0.00005, 0, 0.681, -0.5, -1.3]\n",
    "print(\"neg_Ln_likelihood is:\", neg_ln_likelihood(initial_guess, data, np.linalg.inv(np.diag(dmb**2))))\n",
    "\n",
    "\n",
    "# Run the optimizer\n",
    "result = minimize(neg_ln_likelihood, initial_guess, args=(data, cov_inv), method='Powell') # , method='Powell'\n",
    "# Optimized parameters\n",
    "optimized_params = result.x\n",
    "optimized_log_likelihood = -result.fun\n",
    "\n",
    "print(\"Optimized Parameters:\", optimized_params)\n",
    "print(\"Optimized Log Likelihood:\", optimized_log_likelihood)\n",
    "\n",
    "# Best fit parameters\n",
    "#print(f\"Best fit parameters: H0 = {best_fit_params[0]}, Om0 = {best_fit_params[1]}\")\n",
    "print(f\"Best fit parameters: H0 = {optimized_params[0]}, Omega_matter = {optimized_params[1]}, Omega_rad = {optimized_params[2]}, Omega_k = {optimized_params[3]}, Omega_L = {optimized_params[4]}, w0 = {optimized_params[5]}, wa = {optimized_params[6]}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model predictions using the best fit parameters\n",
    "#z = data['zcmb'].values\n",
    "H0_best, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best = optimized_params\n",
    "mu_best = []\n",
    "for z_prime in z_list:\n",
    "    mu_best.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best, H0_best)*(1+z_prime)) + 25)\n",
    "\n",
    "# mb is mu +19.3, so:\n",
    "y = data['mb'].values # cfr. Mari\n",
    "#xerr = data['dz'].values\n",
    "\n",
    "# Plot the observed data and model predictions\n",
    "plt.errorbar(z, y, yerr=data['dmb'], fmt='o', label='Observed Data')\n",
    "plt.plot(z_list, mu_best, 'r-', label='Best Fit Model')\n",
    "plt.xlabel('Redshift (z)')\n",
    "plt.ylabel('Distance Modulus (mu)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the first part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to study the data file \"binned_data.txt\" in more detail. To do this I will copy the previous code but in the Likelihood we put mb as the data (and not my computed distances)\n",
    "\n",
    "N.B: First of all I will study with the simplified Likelihood (only Gaussian part --> Chi Square)\n",
    "\n",
    "N.B: Then we will study with the complete Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel the previous data (in this way we can use mb and not mu)\n",
    "data = []\n",
    "d = []\n",
    "z_list = []\n",
    "dmb = []\n",
    "\n",
    "# READ THE DATA\n",
    "# Load the data\n",
    "file_path = 'binned_data.txt'\n",
    "\n",
    "# Read the first line to get the header\n",
    "with open(file_path, 'r') as file:\n",
    "    header_line = file.readline().strip()\n",
    "    header = header_line.lstrip('#').strip()\n",
    "\n",
    "# Remove the last word from the header (assumed to be 'biascor')\n",
    "header_words = header.split()\n",
    "header_words.pop()\n",
    "header = ' '.join(header_words)\n",
    "\n",
    "# Read the rest of the file into a DataFrame\n",
    "data = pd.read_csv(file_path, sep='\\s+', skiprows=1, header=None)\n",
    "data.columns = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Hubble function and set the cosmology\n",
    "def hubble_function_w0wa(z, Omega_m, Omega_r, Omega_k, Omega_lambda, w0, wa, H0):\n",
    "    # Calculate the dark energy contribution\n",
    "    dark_energy_contribution = (1 + z)**(3 * (1 + w0 + wa)) * np.exp(-3 * wa * z / (1 + z))\n",
    "    \n",
    "    # Calculate H(z)\n",
    "    Hz = H0 * np.sqrt(\n",
    "        Omega_m * (1 + z)**3 +\n",
    "        Omega_r * (1 + z)**4 +\n",
    "        Omega_k * (1 + z)**2 +\n",
    "        Omega_lambda * dark_energy_contribution\n",
    "    )\n",
    "    \n",
    "    return Hz\n",
    "\n",
    "'''\n",
    "# Set the cosmology\n",
    "H0 = 67.5\n",
    "omega_matter = 0.319\n",
    "omega_rad = 2.47e-5/(0.672)**2 # 0.00005 \n",
    "omega_k = 0\n",
    "omega_L = 0.681 # 1 - omega_matter - omega_rad - omega_k\n",
    "w0 = -0.5\n",
    "wa = -1.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "#d = data['mb'].values\n",
    "#dmb = data['dmb'].values\n",
    "#z_list = data['zcmb'].values\n",
    "'''\n",
    "mu = []\n",
    "for z_prime in z_list:\n",
    "    mu.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25) #mu.append(5*np.log10(Dc(hubble_function,z_prime,0.319,0,-1,68)*(1+z_prime)) + 25)\n",
    "'''\n",
    "# Define the likelihood function\n",
    "def ln_likelihood(params, data, cov_inv):\n",
    "    H0, Omega_mat, Omega_rad, Omega_k, Omega_L, w0, wa = params \n",
    "    #print(H0, Omega_mat, Omega_rad, Omega_k, Omega_L, w0, wa)\n",
    "    # Check if the parameters are within the physical range\n",
    "    if Omega_mat and Omega_rad and Omega_k and Omega_L < 0: #METTERE OR e METTERE PIU IF\n",
    "        return -np.inf\n",
    "    if w0 < -2 or w0 > 0:\n",
    "        return -np.inf\n",
    "    if wa < -3 or wa > 0:\n",
    "        return -np.inf\n",
    "    if H0 < 0 and H0 > 100:\n",
    "        return -np.inf\n",
    "    d = data['mb'].values + 19.3\n",
    "    mu = []\n",
    "    for z_prime in z_list:\n",
    "        mu.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25) #it is equivalent to get_mu(z, H0, Om0, w0, wa)\n",
    "    diff = d - mu\n",
    "    term1 = -0.5 * diff @ cov_inv @ diff \n",
    "    \n",
    "    return term1 \n",
    "\n",
    "def neg_ln_likelihood(params, data, cov_inv):\n",
    "    return -2*ln_likelihood(params, data, cov_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data and covariance inverse matrix\n",
    "d = data['mb'].values + 19.3\n",
    "dmb = data['dmb'].values\n",
    "z_list = data['zcmb'].values\n",
    "\n",
    "# Compute the covariance matrix\n",
    "Sigma = np.diag(dmb**2)\n",
    "cov_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "# Initial guess for the parameters [H0, Om0]\n",
    "initial_guess = [67.5, 0.319, 0.00005, 0., 0.681, -0.5, -1.3]\n",
    "print(\"neg_Ln_likelihood is:\", neg_ln_likelihood(initial_guess, data, np.linalg.inv(np.diag(dmb**2))))\n",
    "\n",
    "\n",
    "# Run the optimizer\n",
    "result = minimize(neg_ln_likelihood, initial_guess, args=(data, cov_inv), method='Powell') # , method='Powell'\n",
    "# Optimized parameters\n",
    "optimized_params = result.x\n",
    "optimized_log_likelihood = -result.fun\n",
    "\n",
    "print(\"Optimized Parameters:\", optimized_params)\n",
    "print(\"Optimized Log Likelihood:\", optimized_log_likelihood)\n",
    "\n",
    "# Best fit parameters\n",
    "#print(f\"Best fit parameters: H0 = {best_fit_params[0]}, Om0 = {best_fit_params[1]}\")\n",
    "print(f\"Best fit parameters: H0 = {optimized_params[0]}, Omega_matter = {optimized_params[1]}, Omega_rad = {optimized_params[2]}, Omega_k = {optimized_params[3]}, Omega_L = {optimized_params[4]}, w0 = {optimized_params[5]}, wa = {optimized_params[6]}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model predictions using the best fit parameters\n",
    "#z = data['zcmb'].values\n",
    "H0_best, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best = optimized_params\n",
    "mu_best = []\n",
    "for z_prime in z_list:\n",
    "    mu_best.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best, H0_best)*(1+z_prime)) + 25)\n",
    "\n",
    "# mb is mu +19.3, so:\n",
    "y = data['mb'].values + 19.3 # cfr. Mari\n",
    "#xerr = data['dz'].values\n",
    "\n",
    "# Plot the observed data and model predictions\n",
    "plt.errorbar(z, y, yerr=data['dmb'], fmt='o', label='Observed Data')\n",
    "plt.plot(z_list, mu_best, 'r-', label='Best Fit Model')\n",
    "plt.xlabel('Redshift (z)')\n",
    "plt.ylabel('Distance Modulus (mu)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I try to do the same thing but I will change redshifts, i.e. I will take the file with more data: \"lcparam_full_long\" and then we will do 2 cases:\n",
    "\n",
    "* 1- I will choose only redshifts smaller than 0.3\n",
    "* 2- I will choose only redshifts greater than 0.3\n",
    "\n",
    "With this method we can understand if it is convenient observ Supernovae at low or high redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At low redshift (< 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel the previous data (in this way we can use mb and not mu)\n",
    "data = []\n",
    "d = []\n",
    "z_list = []\n",
    "dmb = []\n",
    "\n",
    "# READ THE DATA\n",
    "# Load the data\n",
    "file_path = 'lcparam_full_long.txt'\n",
    "\n",
    "# Read the first line to get the header\n",
    "with open(file_path, 'r') as file:\n",
    "    header_line = file.readline().strip()\n",
    "    header = header_line.lstrip('#').strip()\n",
    "\n",
    "# Remove the last word from the header (assumed to be 'biascor')\n",
    "header_words = header.split()\n",
    "header_words.pop()\n",
    "header = ' '.join(header_words)\n",
    "\n",
    "# Read the rest of the file into a DataFrame\n",
    "data = pd.read_csv(file_path, sep='\\s+', skiprows=1, header=None)\n",
    "data.columns = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Hubble function and set the cosmology\n",
    "def hubble_function_w0wa(z, Omega_m, Omega_r, Omega_k, Omega_lambda, w0, wa, H0):\n",
    "    # Calculate the dark energy contribution\n",
    "    dark_energy_contribution = (1 + z)**(3 * (1 + w0 + wa)) * np.exp(-3 * wa * z / (1 + z))\n",
    "    \n",
    "    # Calculate H(z)\n",
    "    Hz = H0 * np.sqrt(\n",
    "        Omega_m * (1 + z)**3 +\n",
    "        Omega_r * (1 + z)**4 +\n",
    "        Omega_k * (1 + z)**2 +\n",
    "        Omega_lambda * dark_energy_contribution\n",
    "    )\n",
    "    \n",
    "    return Hz\n",
    "\n",
    "'''\n",
    "# Set the cosmology\n",
    "H0 = 67.5\n",
    "omega_matter = 0.319\n",
    "omega_rad = 2.47e-5/(0.672)**2 # 0.00005 \n",
    "omega_k = 0\n",
    "omega_L = 0.681 # 1 - omega_matter - omega_rad - omega_k\n",
    "w0 = -0.5\n",
    "wa = -1.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will red the file \"lcparam_full_long\" and create 2 files: \"lcparam_z_low\", \"lcaparam_z_high\" where I put the data with z > 0.3 and the data with z < 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns (i want to take only redshifts greater than 0.3)\n",
    "name = data['name']\n",
    "zcmb = data['zcmb'].values\n",
    "zhel = data['zhel'].values\n",
    "dz = data['dz'].values\n",
    "mb = data['mb'].values\n",
    "dmb = data['dmb'].values\n",
    "x1 = data['x1'].values\n",
    "dx1 = data['dx1'].values\n",
    "color = data['color'].values\n",
    "dcolor = data['dcolor'].values\n",
    "rdvar = data['3rdvar'].values\n",
    "d3rdvar = data['d3rdvar'].values\n",
    "cov_m_s = data['cov_m_s'].values\n",
    "cov_m_c = data['cov_m_c'].values\n",
    "cov_s_c = data['cov_s_c'].values\n",
    "set = data['set'].values\n",
    "ra = data['ra'].values\n",
    "dec = data['dec'].values\n",
    "#biascor = data['biascor'].values\n",
    "\n",
    "f1 = open(\"lcparam_z_low.txt\",\"w\")\n",
    "f2 = open(\"lcparam_z_high.txt\",\"w\")\n",
    "\n",
    "f1.write(\"#name zcmb zhel dz mb dmb x1 dx1 color dcolor 3rdvar d3rdvar cov_m_s cov_m_c cov_s_c set ra dec biascor\"+\"\\n\")\n",
    "f2.write(\"#name zcmb zhel dz mb dmb x1 dx1 color dcolor 3rdvar d3rdvar cov_m_s cov_m_c cov_s_c set ra dec biascor\"+\"\\n\")\n",
    "\n",
    "for i in range(len(zcmb)):\n",
    "    if zcmb[i] < 0.3:\n",
    "        f1.write(str(name[i]) + \"  \" + str(zcmb[i]) + \" \" + str(zhel[i]) + \" \" + str(dz[i]) + \" \" + str(mb[i]) + \" \" + str(dmb[i]) + \" \" + str(x1[i]) + \" \" + str(dx1[i]) + \" \" + str(color[i]) + \" \" + str(dcolor[i]) + \" \" + str(rdvar[i]) + \" \" + str(d3rdvar[i]) + \" \" + str(cov_m_s[i]) + \" \" + str(cov_m_c[i]) + \" \" + str(cov_s_c[i]) + \" \" + str(set[i]) + \" \" + str(ra[i]) + \" \" + str(dec[i]) + \"\\n\" )\n",
    "        \n",
    "    else:\n",
    "        f2.write(str(name[i]) + \"  \" + str(zcmb[i]) + \" \" + str(zhel[i]) + \" \" + str(dz[i]) + \" \" + str(mb[i]) + \" \" + str(dmb[i]) + \" \" + str(x1[i]) + \" \" + str(dx1[i]) + \" \" + str(color[i]) + \" \" + str(dcolor[i]) + \" \" + str(rdvar[i]) + \" \" + str(d3rdvar[i]) + \" \" + str(cov_m_s[i]) + \" \" + str(cov_m_c[i]) + \" \" + str(cov_s_c[i]) + \" \" + str(set[i]) + \" \" + str(ra[i]) + \" \" + str(dec[i]) + \"\\n\" )\n",
    "        \n",
    "f1.close()\n",
    "f2.close()\n",
    "\n",
    "#Now I read the file: 'lcparam_z_low.txt' with pandas\n",
    "\n",
    "# READ THE DATA\n",
    "# Load the data\n",
    "file_path = 'lcparam_z_low.txt'\n",
    "\n",
    "# Read the first line to get the header\n",
    "with open(file_path, 'r') as file:\n",
    "    header_line = file.readline().strip()\n",
    "    header = header_line.lstrip('#').strip()\n",
    "\n",
    "# Remove the last word from the header (assumed to be 'biascor')\n",
    "header_words = header.split()\n",
    "header_words.pop()\n",
    "header = ' '.join(header_words)\n",
    "\n",
    "# Read the rest of the file into a DataFrame\n",
    "data_low = pd.read_csv(file_path, sep='\\s+', skiprows=1, header=None)\n",
    "data_low.columns = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the likelihood\n",
    "z_low = data_low['zcmb'].values\n",
    "'''\n",
    "mu_low = []\n",
    "for z_prime in z_low:\n",
    "    mu_low.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25)\n",
    "\n",
    "print(len(z_low)) # 630, 392\n",
    "print(len(mu_low))\n",
    "'''\n",
    "\n",
    "# Define the likelihood function\n",
    "def ln_likelihood(params, data, cov_inv):\n",
    "    H0, Omega_mat, Omega_rad, Omega_k, Omega_L, w0, wa = params \n",
    "    #print(H0, Omega_mat, Omega_rad, Omega_k, Omega_L, w0, wa)\n",
    "    # Check if the parameters are within the physical range\n",
    "    if Omega_mat < 0:\n",
    "        return -np.inf\n",
    "    if Omega_rad < 0:\n",
    "        return -np.inf\n",
    "    if Omega_k < 0:\n",
    "        return -np.inf\n",
    "    if Omega_L < 0:\n",
    "        return -np.inf\n",
    "    if w0 < -2 or w0 > 0:\n",
    "        return -np.inf\n",
    "    if wa < -3 or wa > 0:\n",
    "        return -np.inf\n",
    "    if H0 < 0 and H0 > 100:\n",
    "        return -np.inf\n",
    "    d = data['mb'].values + 19.3\n",
    "    mu_low = []\n",
    "    for z_prime in z_low:\n",
    "        mu_low.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25) #it is equivalent to get_mu(z, H0, Om0, w0, wa)\n",
    "    diff = d - mu_low\n",
    "    term1 = -0.5 * diff @ cov_inv @ diff \n",
    "    \n",
    "    return term1 \n",
    "\n",
    "def neg_ln_likelihood(params, data, cov_inv):\n",
    "    return -2*ln_likelihood(params, data, cov_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data and covariance inverse matrix\n",
    "#d = data['mb'].values + 19.3\n",
    "dmb_low = data_low['dmb'].values\n",
    "#z_list = data['zcmb'].values\n",
    "\n",
    "# Compute the covariance matrix\n",
    "Sigma = np.diag(dmb_low**2)\n",
    "cov_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "# Initial guess for the parameters [H0, Om0]\n",
    "initial_guess = [67.5, 0.319, 0.00005, 0., 0.681, -0.5, -1.3]\n",
    "print(\"neg_Ln_likelihood is:\", neg_ln_likelihood(initial_guess, data_low, cov_inv))\n",
    "\n",
    "\n",
    "# Run the optimizer\n",
    "result = minimize(neg_ln_likelihood, initial_guess, args=(data_low, cov_inv), method='Powell') # , method='Powell'\n",
    "# Optimized parameters\n",
    "optimized_params = result.x\n",
    "optimized_log_likelihood = -result.fun\n",
    "\n",
    "print(\"Optimized Parameters:\", optimized_params)\n",
    "print(\"Optimized Log Likelihood:\", optimized_log_likelihood)\n",
    "\n",
    "# Best fit parameters\n",
    "#print(f\"Best fit parameters: H0 = {best_fit_params[0]}, Om0 = {best_fit_params[1]}\")\n",
    "print(f\"Best fit parameters: H0 = {optimized_params[0]}, Omega_matter = {optimized_params[1]}, Omega_rad = {optimized_params[2]}, Omega_k = {optimized_params[3]}, Omega_L = {optimized_params[4]}, w0 = {optimized_params[5]}, wa = {optimized_params[6]}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model predictions using the best fit parameters\n",
    "#z = data['zcmb'].values\n",
    "H0_best, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best = optimized_params\n",
    "mu_best = []\n",
    "for z_prime in z_low:\n",
    "    mu_best.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best, H0_best)*(1+z_prime)) + 25)\n",
    "\n",
    "# mb is mu +19.3, so:\n",
    "y = data_low['mb'].values + 19.3 # cfr. Mari\n",
    "#xerr = data['dz'].values\n",
    "\n",
    "# Plot the observed data and model predictions\n",
    "plt.errorbar(z_low, y, yerr=data_low['dmb'], fmt='o', label='Observed Data')\n",
    "plt.plot(z_low, mu_best, 'r-', label='Best Fit Model')\n",
    "plt.xlabel('Redshift (z)')\n",
    "plt.ylabel('Distance Modulus (mu)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At high redshift (z > 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ THE DATA\n",
    "# Load the data\n",
    "file_path = 'lcparam_z_high.txt'\n",
    "\n",
    "# Read the first line to get the header\n",
    "with open(file_path, 'r') as file:\n",
    "    header_line = file.readline().strip()\n",
    "    header = header_line.lstrip('#').strip()\n",
    "\n",
    "# Remove the last word from the header (assumed to be 'biascor')\n",
    "header_words = header.split()\n",
    "header_words.pop()\n",
    "header = ' '.join(header_words)\n",
    "\n",
    "# Read the rest of the file into a DataFrame\n",
    "data_high = pd.read_csv(file_path, sep='\\s+', skiprows=1, header=None)\n",
    "data_high.columns = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Hubble function and set the cosmology\n",
    "def hubble_function_w0wa(z, Omega_m, Omega_r, Omega_k, Omega_lambda, w0, wa, H0):\n",
    "    # Calculate the dark energy contribution\n",
    "    dark_energy_contribution = (1 + z)**(3 * (1 + w0 + wa)) * np.exp(-3 * wa * z / (1 + z))\n",
    "    \n",
    "    # Calculate H(z)\n",
    "    Hz = H0 * np.sqrt(\n",
    "        Omega_m * (1 + z)**3 +\n",
    "        Omega_r * (1 + z)**4 +\n",
    "        Omega_k * (1 + z)**2 +\n",
    "        Omega_lambda * dark_energy_contribution\n",
    "    )\n",
    "    \n",
    "    return Hz\n",
    "\n",
    "'''\n",
    "# Set the cosmology\n",
    "H0 = 67.5\n",
    "omega_matter = 0.319\n",
    "omega_rad = 2.47e-5/(0.672)**2 # 0.00005 \n",
    "omega_k = 0\n",
    "omega_L = 0.681 # 1 - omega_matter - omega_rad - omega_k\n",
    "w0 = -0.5\n",
    "wa = -1.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the likelihood\n",
    "z_high = data_high['zcmb'].values\n",
    "'''\n",
    "mu_low = []\n",
    "for z_prime in z_high:\n",
    "    mu_low.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25)\n",
    "\n",
    "print(len(z_high)) # 630, 392\n",
    "print(len(mu_high))\n",
    "'''\n",
    "\n",
    "# Define the likelihood function\n",
    "def ln_likelihood(params, data, cov_inv):\n",
    "    H0, Omega_mat, Omega_rad, Omega_k, Omega_L, w0, wa = params \n",
    "    print(H0, Omega_mat, Omega_rad, Omega_k, Omega_L, w0, wa)\n",
    "    # Check if the parameters are within the physical range\n",
    "    if Omega_mat < 0:\n",
    "        return -np.inf\n",
    "    if Omega_rad < 0:\n",
    "        return -np.inf\n",
    "    if Omega_k < 0:\n",
    "        return -np.inf\n",
    "    if Omega_L < 0:\n",
    "        return -np.inf\n",
    "    if w0 < -2 or w0 > 0:\n",
    "        return -np.inf\n",
    "    if wa < -3 or wa > 0:\n",
    "        return -np.inf\n",
    "    if H0 < 0 and H0 > 100:\n",
    "        return -np.inf\n",
    "    d = data['mb'].values + 19.3\n",
    "    mu_high = []\n",
    "    for z_prime in z_high:\n",
    "        mu_high.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, omega_matter, omega_rad, omega_k, omega_L, w0, wa, H0)*(1+z_prime)) + 25) #it is equivalent to get_mu(z, H0, Om0, w0, wa)\n",
    "    diff = d - mu_high\n",
    "    term1 = -0.5 * diff @ cov_inv @ diff \n",
    "    \n",
    "    return term1 \n",
    "\n",
    "def neg_ln_likelihood(params, data, cov_inv):\n",
    "    return -2*ln_likelihood(params, data, cov_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data and covariance inverse matrix\n",
    "#d = data['mb'].values + 19.3\n",
    "dmb_high = data_high['dmb'].values\n",
    "#z_list = data['zcmb'].values\n",
    "\n",
    "# Compute the covariance matrix\n",
    "Sigma = np.diag(dmb_high**2)\n",
    "cov_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "# Initial guess for the parameters [H0, Om0]\n",
    "initial_guess = [67.5, 0.319, 0.00005, 0., 0.681, -0.5, -1.3]\n",
    "print(\"neg_Ln_likelihood is:\", neg_ln_likelihood(initial_guess, data_high, cov_inv))\n",
    "\n",
    "\n",
    "# Run the optimizer\n",
    "result = minimize(neg_ln_likelihood, initial_guess, args=(data_high, cov_inv), method='Powell') # , method='Powell'\n",
    "# Optimized parameters\n",
    "optimized_params = result.x\n",
    "optimized_log_likelihood = -result.fun\n",
    "\n",
    "print(\"Optimized Parameters:\", optimized_params)\n",
    "print(\"Optimized Log Likelihood:\", optimized_log_likelihood)\n",
    "\n",
    "# Best fit parameters\n",
    "#print(f\"Best fit parameters: H0 = {best_fit_params[0]}, Om0 = {best_fit_params[1]}\")\n",
    "print(f\"Best fit parameters: H0 = {optimized_params[0]}, Omega_matter = {optimized_params[1]}, Omega_rad = {optimized_params[2]}, Omega_k = {optimized_params[3]}, Omega_L = {optimized_params[4]}, w0 = {optimized_params[5]}, wa = {optimized_params[6]}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model predictions using the best fit parameters\n",
    "#z = data['zcmb'].values\n",
    "H0_best, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best = optimized_params\n",
    "mu_best = []\n",
    "for z_prime in z_high:\n",
    "    mu_best.append(5*np.log10(Dc_w0wa(hubble_function_w0wa, z_prime, Omega_matter_best, Omega_rad_best, Omega_k_best, Omega_L_best, w0_best, wa_best, H0_best)*(1+z_prime)) + 25)\n",
    "\n",
    "# mb is mu +19.3, so:\n",
    "y = data_high['mb'].values + 19.3 # cfr. Mari\n",
    "#xerr = data['dz'].values\n",
    "\n",
    "# Plot the observed data and model predictions\n",
    "plt.errorbar(z_high, y, yerr=data_high['dmb'], fmt='o', label='Observed Data')\n",
    "plt.plot(z_high, mu_best, 'r-', label='Best Fit Model')\n",
    "#plt.scatter(z_high, mu_best, marker='o', label='Best Fit Model') #cfr.code of week6 to make a better scatter plot\n",
    "plt.xlabel('Redshift (z)')\n",
    "plt.ylabel('Distance Modulus (mu)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cose nuove che voglio fare:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vedere come cambia il valore di H0 se cambia mag assoluta M (farlo con tutti gli z, non con low e high)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non usare piu minimize ma fare mcmc cosi che, oltre al valore best di H0 e altri parametri, posso ottenre una distribuzione del parametro (valore medio, incertezza, skewness, ...)\n",
    "\n",
    "ATTENZIONE: togliere H0 dai params perche dipende troppo da Mag assoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
